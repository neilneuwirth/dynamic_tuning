{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156653a0",
   "metadata": {},
   "source": [
    "\n",
    "### Setup\n",
    "\n",
    "In this section, we set up our environment by importing necessary libraries and configurations. We also suppress specific warnings to ensure a clean output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121badb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba9bc4",
   "metadata": {},
   "source": [
    "\n",
    "### Scraping Reviews from Rotten Tomatoes\n",
    "\n",
    "To analyze the writing style of different critics, we start by scraping reviews from Rotten Tomatoes for a list of specified critics. This data will serve as our base for further analysis and interaction with the language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616764a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITICS = {\n",
    "    \"REUBEN BARON\": \"https://www.rottentomatoes.com/critics/reuben-baron/movies\",\n",
    "    \"RON SEOUL-OH\": \"https://www.rottentomatoes.com/critics/ron-seoul-oh/movies\",\n",
    "    \"LINDA MARRIC\": \"https://www.rottentomatoes.com/critics/linda-marric/movies\",\n",
    "    \"ISHITA SENGUPTA\": \"https://www.rottentomatoes.com/critics/ishita-sengupta/movies\",\n",
    "    \"GANESH AAGLAVE\": \"https://www.rottentomatoes.com/critics/ganesh-aaglave/movies\",\n",
    "    \"DANA KENNEDY\": \"https://www.rottentomatoes.com/critics/dana-kennedy/movies\",\n",
    "    \"NATALIA KEOGAN\": \"https://www.rottentomatoes.com/critics/natalia-keogan/movies\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3492d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for critic, url in CRITICS.items():\n",
    "    tmp_df = pd.read_html(url)[0]\n",
    "    tmp_df['Critic'] = critic\n",
    "    data = data.append(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f45fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae3c81",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning and Transformation\n",
    "\n",
    "After scraping the reviews, we need to clean and transform the data to make it suitable for analysis. The first step is to normalize the ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rating(rating):\n",
    "    \"\"\"\n",
    "    Normalize a rating represented as a string fraction or a zero value.\n",
    "    \n",
    "    Examples:\n",
    "        >>> normalize_rating('1/5')\n",
    "        20.0\n",
    "        >>> normalize_rating('2/0')\n",
    "        None\n",
    "        >>> normalize_rating(0)\n",
    "        0.0\n",
    "        >>> normalize_rating('invalid_string')\n",
    "        None\n",
    "    \"\"\"\n",
    "    if isinstance(rating, str) and '/' in rating:\n",
    "        try:\n",
    "            numerator, denominator = map(float, rating.split('/'))\n",
    "            if denominator != 0:  # Avoid division by zero\n",
    "                return (numerator / denominator) * 100\n",
    "        except ValueError:  # Handle cases where the string isn't two numbers separated by '/'\n",
    "            return None\n",
    "    elif rating == 0:\n",
    "        return 0.0\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rating'] = data.Rating.apply(normalize_rating)\n",
    "data = data.dropna(subset=['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc935a2f",
   "metadata": {},
   "source": [
    "\n",
    "Next, we categorize the normalized ratings into sentiment bins, extract movie titles and years, and count the number of reviews for each critic. We also remove any unnecessary columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e86aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and labels for sentiment categorization\n",
    "bins = [-1, 50, 70, 90, 100]  # We use -1 as the start to include 0 in the first bin\n",
    "labels = ['bad', 'neutral', 'positive', 'very positive']\n",
    "\n",
    "data['Sentiment'] = pd.cut(data['Rating'], bins=bins, labels=labels, right=True)\n",
    "data[['Title', 'Year']] = data['Title | Year'].str.extract(r'(.+)\\s\\((\\d{4})\\)')\n",
    "data['critic_count'] = data.groupby('Critic')['Critic'].transform('count')\n",
    "data.drop(columns=['Title | Year', 'T-Meter'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba932d",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae69101",
   "metadata": {},
   "source": [
    "First, we filter out critics with fewer reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6bffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to keep critics with a minimum number of reviews\n",
    "MIN_REVIEWS = 5\n",
    "filter_mask = (data.critic_count >= MIN_REVIEWS)\n",
    "data = data[filter_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265c4b0",
   "metadata": {},
   "source": [
    "Next, we augment each row with additional context. This helps in better understanding the sentiment and rating associated with each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8269b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_context(row):\n",
    "    return f\"\"\"\n",
    "    CRITIC: {row['Critic']}\n",
    "    RATING: {row['Rating']}\n",
    "    SENTIMENT: {row['Sentiment']}\n",
    "    MOVIE: {row['Title']}\n",
    "    YEAR: {row['Year']}\n",
    "    REVIEW: {row['Review']}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Context'] = data.apply(augment_context, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79660705",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f2816",
   "metadata": {},
   "source": [
    "\n",
    "### Vector Store Configuration\n",
    "\n",
    "To enable semantic search over our dataset, we utilize a vector store. This allows us to efficiently find reviews that are semantically similar to a given query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa7aab6",
   "metadata": {},
   "source": [
    "\n",
    "We'll generate embeddings for each review. These embeddings are dense vector representations that capture the semantic meaning of the text. They will be used for similarity searches in the vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from config import get_embedding, get_chat_completion\n",
    "\n",
    "data[\"embeddings\"] = data[\"Context\"].progress_apply(get_embedding)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd691452",
   "metadata": {},
   "source": [
    "\n",
    "With the embeddings generated, we can now configure and set up the vector store. This will allow us to efficiently query reviews based on semantic similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b30d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient()\n",
    "collection = client.get_or_create_collection(\"rotten_tomatoes_reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69772bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = data.embeddings.values.tolist()\n",
    "ids = data.index.astype(str).values.tolist()\n",
    "documents = data.Context.values.tolist()\n",
    "metadata = data[['Rating', 'Review', 'Critic', 'Sentiment', 'Title', 'Year', 'critic_count', 'Context']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    metadatas=metadata,\n",
    "    documents=documents,\n",
    "    ids=ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdd907",
   "metadata": {},
   "source": [
    "\n",
    "### Sample Run\n",
    "\n",
    "In this demonstration, we illustrate the end-to-end process of crafting a review in the style of a chosen critic using the LLM. We utilize the vector store to fetch reviews that match the critic's style and construct a few-shot prompt to guide the LLM's response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8dd70",
   "metadata": {},
   "source": [
    "\n",
    "#### Selection\n",
    "\n",
    "First, we choose a critic, sentiment, movie, and draft the initial review details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f050e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Critic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33beb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITIC = \"NATALIA KEOGAN\"\n",
    "SENTIMENT = \"positive\"\n",
    "MOVIE = \"Whispers of the Nebula\"\n",
    "MOVIE_DESCRIPTION = \"\"\"In a distant future, a renowned astronaut discovers an ancient alien civilization within a mesmerizing nebula, only to realize that the echoes of their history hold the key to saving Earth from an impending cosmic disaster.\"\"\"\n",
    "REVIEW_ROUGH_DRAFT = \"\"\"\n",
    "- Cool space adventures meet old alien secrets.\n",
    "- Makes you think about Earth's place in space.\n",
    "- Mixes space tales with ancient puzzles.\n",
    "\"\"\"\n",
    "INITIAL_PROMPT = f\"\"\"\n",
    "Write a {SENTIMENT} review about a {MOVIE}. I want you to write the review in the style of {CRITIC}.\n",
    "\n",
    "The movie description is: {MOVIE_DESCRIPTION}\n",
    "\n",
    "Here are things I want to hit on in my review: {REVIEW_ROUGH_DRAFT}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4f7654",
   "metadata": {},
   "source": [
    "\n",
    "#### Few-Shot Prompting\n",
    "\n",
    "Constructing the few-shot prompt by incorporating the retrieved reviews from the vector store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1adaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "HERE IS MY TASK: {prompt}\n",
    "\n",
    "==== EXAMPLE OUTPUTS ====\n",
    "{few_shot_examples}\n",
    "===== END OF EXAMPLE OUTPUTS =====\n",
    "\n",
    "Mirror the example outputs given and return one response. Think step-by-step about how you would respond to the prompt. OUTPUT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3ccae",
   "metadata": {},
   "source": [
    "\n",
    "#### Semantic Search\n",
    "\n",
    "We use the vector store to retrieve top reviews that match the style of the chosen critic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9223ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "prompt_embedding = get_embedding(INITIAL_PROMPT)\n",
    "query_result = collection.query(prompt_embedding, n_results=TOP_K, include=[\"documents\", \"distances\", \"metadatas\"], where={\"Critic\": CRITIC})\n",
    "\n",
    "few_shot_examples = \"\"\" \"\"\"\n",
    "for i, result in enumerate(query_result[\"metadatas\"][0]):\n",
    "    review = f\"\"\"\n",
    "    Example Output {i + 1}: {result[\"Review\"]}\n",
    "    \"\"\"\n",
    "    few_shot_examples += review\n",
    "\n",
    "prompt = prompt_template.format(prompt=INITIAL_PROMPT, few_shot_examples=few_shot_examples)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601242c0",
   "metadata": {},
   "source": [
    "#### Interacting with the LLM\n",
    "We send the few-shot prompt to the LLM to get a review for the chosen movie in the style of the selected critic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562efa4",
   "metadata": {},
   "source": [
    "Zero-Shot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e46cd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": INITIAL_PROMPT}]\n",
    "zero_shot_output = get_chat_completion(messages, model=\"gpt-4\")\n",
    "print(zero_shot_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf370d4",
   "metadata": {},
   "source": [
    "**Few-Shot Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "few_shot_output = get_chat_completion(messages, model=\"gpt-4\")\n",
    "print(few_shot_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
